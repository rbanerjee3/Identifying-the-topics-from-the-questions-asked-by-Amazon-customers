{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the topics based on questions asked by Amazon customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is topic modelling?\n",
    "It is an unsupervised approach used for finding and observing the bunch of words (called Topics) in large clusters of texts.\n",
    "\n",
    "### Algorithm used:\n",
    "There are many algorithms available for Topic Modelling such as LSA (Latent Semantic Analysis), NMF (Non-Matrix Factorization) and LDA (Latent Dirichlet Algorithm). I'm using LDA as it provides more accurate results and scales well for large text corpuses.\n",
    "\n",
    "### A brief intro to LDA algorithm:\n",
    "LDA is a matrix factorization technique which assumes sentences are made up of mixture of words and tries to figure out what words would create those sentences in the first place. It is based on probabilistic graphical modelling. The algorithm works as follows:<br>\n",
    "1. In the initialization stage, each word is assigned to a random topic.\n",
    "2. Iteratively, the algorithm goes through each word and reassigns the word to a topic taking into consideration:<br>\n",
    "    What’s the probability of the word belonging to a topic?<br>\n",
    "    What’s the probability of the document to be generated by a topic?\n",
    "[Source]('https://nlpforhackers.io/topic-modeling/')\n",
    "\n",
    "### Data Source:\n",
    "http://jmcauley.ucsd.edu/data/amazon/qa/. Click on the Automotive category file to download the json file having the customer queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rupamanupbanerjee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read the zip files\n",
    "import gzip\n",
    "\n",
    "#LDA model\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Visualizing LDA\n",
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Import the data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "data = getDF('qa_Automotive.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Extract the text column and assign it to an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_name):\n",
    "    data_text = data[['question']]\n",
    "    data_text['index'] = data_text.index\n",
    "    return data_text\n",
    "documents=prepare_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the most useful length to get?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are these cables made of copper or aluminum?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought the Red Extra Heavy Duty. Is that too...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi, Being 20ft 4gauge how heavy is this?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do these cables come with a bag?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  index\n",
       "0             What is the most useful length to get?      0\n",
       "1       Are these cables made of copper or aluminum?      1\n",
       "2  I bought the Red Extra Heavy Duty. Is that too...      2\n",
       "3           Hi, Being 20ft 4gauge how heavy is this?      3\n",
       "4                   Do these cables come with a bag?      4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Reducing the words to its common  base form\n",
    "Now, we need to reduce the words which are in its plural or derivational forms into its common base form. This will help us collect the similar words from all the corpuses. Now the question is how do we do that? Here, stemming and lemmatization comes to the rescue.<br><br>\n",
    "**What is Stemming?** <br>\n",
    "The process of chopping off the ends of words, often includes the removal of derivational fixes. E.g. cats -> cat<br>\n",
    "There are two types of stemmer: SnowballStemmer and PorterStemmer. We will be using SnowballStemmer as it gives a more meaningful result compared to PorterStemmer().<br>\n",
    "\n",
    "**What is Lemmatization?** <br>\n",
    "The process of removal of inflectional endings only and returning the base or dictionary form of a word, which is known as lemma. E.g. running -> run.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to remove the stopwords and words whose length is less than or equal to three as they won't add much value to our model. We will implement it using gensim library as it already has a tokenization function and built-in library of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_shortwords(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['It', 'does', 'not', 'state', 'what', 'RPM', 'this', 'motor', 'is,', 'does', 'anyone', 'know?']\n",
      "\n",
      "\n",
      " Tokenized and lemmatized document: \n",
      "['state', 'motor', 'know']\n"
     ]
    }
   ],
   "source": [
    "sample = documents[documents['index'] == 25].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n Tokenized and lemmatized document: ')\n",
    "print(remove_stopwords_and_shortwords(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will apply the same on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['question'].map(remove_stopwords_and_shortwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the processed docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [use, length]\n",
       "1           [cabl, copper, aluminum]\n",
       "2    [buy, extra, heavi, duti, size]\n",
       "3                      [gaug, heavi]\n",
       "4                       [cabl, come]\n",
       "5        [wire, pair, surpris, wire]\n",
       "6                       [amp, handl]\n",
       "7              [cabl, boost, school]\n",
       "8                      [use, length]\n",
       "9           [cabl, copper, aluminum]\n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Build a dictionary of words present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 14469 words in the dictionary.\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "print('There are total '+ str(len(dictionary))+' words in the dictionary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 length\n",
      "1 use\n",
      "2 aluminum\n",
      "3 cabl\n",
      "4 copper\n",
      "5 buy\n",
      "6 duti\n",
      "7 extra\n",
      "8 heavi\n",
      "9 size\n",
      "10 gaug\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, word in dictionary.iteritems():\n",
    "    print(index, word)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Filter the dictionary based on frequency of words. \n",
    "Here, I have ignored the words which have appeared in less than 4 queries and the ones who are present in at most 50% of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of words in the dictionary after filtering: 4705\n"
     ]
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below=4, no_above=0.5)\n",
    "print('No. of words in the dictionary after filtering: '+ str(len(dictionary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Create a list having the index value and the frequency of the word for every question in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(5, 1), (6, 1), (7, 1), (8, 1), (9, 1)],\n",
       " [(8, 1), (10, 1)],\n",
       " [(3, 1), (11, 1)]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"length\") appears 1 time.\n",
      "Word 1 (\"use\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_sample = bow_corpus[0]\n",
    "\n",
    "for i in range(len(bow_doc_sample)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_sample[i][0], \n",
    "                                                     dictionary[bow_doc_sample[i][0]], \n",
    "                                                     bow_doc_sample[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Implement the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(bow_corpus, num_topics=5, id2word=dictionary, passes=5,minimum_probability=0.01, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.038*\"light\" + 0.036*\"bulb\" + 0.034*\"work\" + 0.032*\"toyota\" + 0.019*\"dodg\" + 0.018*\"long\" + 0.018*\"inch\"\n",
      "Topic: 1 \n",
      "Words: 0.036*\"instal\" + 0.030*\"come\" + 0.025*\"mount\" + 0.024*\"need\" + 0.024*\"wire\" + 0.022*\"work\" + 0.021*\"light\"\n",
      "Topic: 2 \n",
      "Words: 0.032*\"size\" + 0.032*\"tire\" + 0.026*\"need\" + 0.019*\"color\" + 0.018*\"order\" + 0.017*\"black\" + 0.015*\"like\"\n",
      "Topic: 3 \n",
      "Words: 0.084*\"work\" + 0.036*\"seat\" + 0.033*\"model\" + 0.026*\"honda\" + 0.021*\"ford\" + 0.021*\"chevi\" + 0.019*\"cover\"\n",
      "Topic: 4 \n",
      "Words: 0.029*\"batteri\" + 0.026*\"say\" + 0.019*\"unit\" + 0.017*\"plug\" + 0.014*\"light\" + 0.014*\"right\" + 0.014*\"charg\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1,num_words=7):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Visualize the topics\n",
    "I have used pyLDAvis library which is designed to help users interpret the topics in a topic model that has been fit to a corpus of text data. The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization.[Source]('https://github.com/bmabey/pyLDAvis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupamanupbanerjee/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/rupamanupbanerjee/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/rupamanupbanerjee/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/rupamanupbanerjee/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/rupamanupbanerjee/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/rupamanupbanerjee/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/rupamanupbanerjee/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/rupamanupbanerjee/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el173461403708876943682594002766\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el173461403708876943682594002766_data = {\"mdsDat\": {\"x\": [0.10539350888612888, 0.24170960299805663, 0.11980850892831926, -0.3225274134445713, -0.14438420736793375], \"y\": [-0.1579349329036755, -0.018243845214819848, 0.274176583528565, 0.1456299925574562, -0.24362779796752576], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [24.507930175856146, 20.964482238303617, 18.59346530616423, 18.42978771488682, 17.504334564789183]}, \"tinfo\": {\"Term\": [\"work\", \"instal\", \"seat\", \"bulb\", \"model\", \"size\", \"tire\", \"instal\", \"mount\", \"wire\", \"switch\", \"bracket\", \"remot\", \"attach\", \"remov\", \"come\", \"includ\", \"need\", \"light\", \"work\", \"batteri\", \"say\", \"plug\", \"right\", \"charg\", \"accord\", \"leav\", \"unit\", \"power\", \"light\", \"size\", \"tire\", \"color\", \"order\", \"black\", \"purchas\", \"wrangler\", \"need\", \"door\", \"look\", \"like\", \"seat\", \"model\", \"chevi\", \"nissan\", \"mirror\", \"mat\", \"engin\", \"work\", \"honda\", \"ford\", \"cover\", \"bulb\", \"toyota\", \"dodg\", \"inch\", \"dimens\", \"ship\", \"hole\", \"long\", \"light\", \"work\"], \"Freq\": [10535.0, 3442.0, 2609.0, 2469.0, 2389.0, 2340.0, 2328.0, 3441.3353449465217, 2356.820020722343, 2302.7583641795795, 1034.004871280347, 838.7897424072191, 807.3012221544715, 777.2414550701664, 962.646259791031, 2903.2581286652553, 1249.5495642688347, 2307.4369041601026, 1985.9425544572002, 2089.202198392258, 2384.156996182466, 2167.7094534170164, 1386.9244150919167, 1178.307163013503, 1173.5853108032663, 966.6582798043737, 867.1256080591604, 1549.899801547044, 1135.378212494611, 1191.627762259679, 2339.914695017342, 2328.1425183480414, 1379.7434961450597, 1310.1814860569953, 1273.7690485263288, 999.562812375065, 952.3957295649133, 1873.7630680146065, 1099.7120252251098, 1116.7908909308019, 1121.6394123823786, 2609.066346283526, 2388.858712615549, 1493.69258494825, 1144.5237204530047, 992.6949467799443, 956.9733014062399, 896.589589108424, 6101.309700258201, 1873.6762088184487, 1505.254902108759, 1378.100110832739, 2469.138587132111, 2225.6441916446597, 1289.8795287619432, 1216.8122587073394, 1030.2009246453945, 1008.0792474470538, 969.9686301795266, 1217.0689083469867, 2585.447549088449, 2344.919650033754], \"Total\": [10535.0, 3442.0, 2609.0, 2469.0, 2389.0, 2340.0, 2328.0, 3442.1545268372906, 2357.6383710308014, 2303.5745386832314, 1034.823088697739, 839.6071598601243, 808.117572529973, 778.0599626801339, 965.0746342643223, 4805.017224217952, 1645.822481849524, 5549.288168858458, 5763.442213791927, 10535.855651908103, 2384.9642340942087, 2168.51773918926, 1387.7346039942481, 1179.115895448344, 1174.3921709698527, 967.4681490559233, 867.9342554398587, 1564.959368333054, 1546.8795105875668, 5763.442213791927, 2340.7076961473394, 2328.936426000719, 1380.5354486621763, 1310.9784618558579, 1274.563091146278, 1000.3613702552636, 953.1864425922354, 5549.288168858458, 1583.8179873000392, 1880.284921174568, 2303.0751473009323, 2609.876268725648, 2389.670200498758, 1494.499865440969, 1145.3316338798502, 993.5045685969684, 957.7829872730317, 897.3990529583319, 10535.855651908103, 2651.8677340963845, 1924.366238215541, 2533.9221148811316, 2469.9564977209857, 2226.458319558454, 1290.6928771759062, 1217.6302488364636, 1031.0155595253768, 1008.8942865109123, 970.7869267579686, 1416.2579274201873, 5763.442213791927, 10535.855651908103], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.3298, -3.7083, -3.7315, -4.5322, -4.7414, -4.7797, -4.8176, -4.6037, -3.4998, -4.3428, -3.7295, -3.8795, -3.8288, -3.5406, -3.6358, -4.0824, -4.2454, -4.2494, -4.4434, -4.552, -3.9713, -4.2825, -4.2341, -3.4393, -3.4444, -3.9675, -4.0193, -4.0475, -4.2899, -4.3382, -3.6615, -4.1944, -4.179, -4.1746, -3.3216, -3.4098, -3.8793, -4.1456, -4.2879, -4.3246, -4.3897, -2.4721, -3.6527, -3.8716, -3.9599, -3.3252, -3.429, -3.9745, -4.0328, -4.1993, -4.221, -4.2596, -4.0326, -3.2792, -3.3768], \"loglift\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4059, 1.4058, 1.4058, 1.4054, 1.4052, 1.4052, 1.4051, 1.4037, 0.9023, 1.1307, 0.5286, 0.3407, -0.2118, 1.562, 1.562, 1.5618, 1.5617, 1.5617, 1.5615, 1.5614, 1.5527, 1.2531, -0.0139, 1.682, 1.682, 1.6818, 1.6818, 1.6817, 1.6816, 1.6815, 0.5966, 1.3176, 1.1614, 0.9629, 1.6909, 1.6909, 1.6907, 1.6905, 1.6904, 1.6904, 1.6903, 1.1449, 1.3438, 1.4456, 1.0821, 1.7424, 1.7424, 1.7421, 1.742, 1.7419, 1.7419, 1.7419, 1.5911, 0.9411, 0.2402]}, \"token.table\": {\"Topic\": [2, 1, 2, 3, 1, 5, 2, 4, 3, 1, 2, 3, 1, 2, 3, 4, 5, 5, 5, 3, 4, 4, 3, 4, 5, 2, 4, 5, 1, 2, 1, 2, 1, 2, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 4, 4, 4, 1, 1, 2, 3, 5, 4, 3, 2, 1, 2, 4, 3, 1, 1, 2, 3, 2, 2, 4, 5, 3, 1, 3, 5, 2, 3, 5, 1, 1, 4, 5, 3], \"Freq\": [0.9995161090766863, 0.9986376851001525, 0.9995957029122599, 0.9995582084949819, 0.9992768524505848, 0.9996127471387175, 0.9996660647273143, 0.9996655299525092, 0.9996121442135403, 0.6041601652057516, 0.213110578426004, 0.18251755593711474, 0.11484173025328012, 0.0015785804845811701, 0.23362991171801317, 0.5438209769382131, 0.10615953758808369, 0.9990149910774923, 0.9994631742468261, 0.6945242501477005, 0.30559067006498825, 0.9995553227329398, 0.2177340215595018, 0.7820756621647976, 0.9991893929179737, 0.2933781311929198, 0.7066717453155934, 0.99948239719154, 0.7594986784937395, 0.2406091813468167, 0.9996645918048451, 0.9989235873178145, 0.34458573996760106, 0.20682084694933558, 0.4485166857080809, 0.2049433777934498, 0.3035072480458081, 0.48717472433103953, 0.00043420207159629195, 0.003907818644366627, 0.14051112876204153, 0.8593067522784147, 0.10530318983588628, 0.23826176286099524, 0.5940589042761868, 0.0005318342921004358, 0.06222461217575099, 0.9991825003331276, 0.9994921325850761, 0.9997195426805683, 0.9997292328464596, 0.41572899618845566, 0.13695450242879337, 0.3377009704625773, 0.10956360194303469, 0.9997104472887676, 0.9992536400220697, 0.9994706451852294, 0.24371646105571618, 0.7337352342128325, 0.021979733888313924, 0.999638760286024, 0.9986170669120903, 0.9978502861948042, 0.0010361892899219151, 0.0010361892899219151, 0.9990536168220177, 0.9997612474272618, 0.9996642489392511, 0.9991135974077077, 0.9996976571878222, 0.9992046092643964, 0.9995979168901887, 0.9997941486016477, 0.9904410500133378, 0.007028936483965623, 0.0025559769032602268, 0.9997505881951796, 0.19827530568166718, 0.5790701962488518, 0.22257328474078963, 0.9987552880116415], \"Term\": [\"accord\", \"attach\", \"batteri\", \"black\", \"bracket\", \"bulb\", \"charg\", \"chevi\", \"color\", \"come\", \"come\", \"come\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"dimens\", \"dodg\", \"door\", \"door\", \"engin\", \"ford\", \"ford\", \"hole\", \"honda\", \"honda\", \"inch\", \"includ\", \"includ\", \"instal\", \"leav\", \"light\", \"light\", \"light\", \"like\", \"like\", \"like\", \"like\", \"like\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"mat\", \"mirror\", \"model\", \"mount\", \"need\", \"need\", \"need\", \"need\", \"nissan\", \"order\", \"plug\", \"power\", \"power\", \"power\", \"purchas\", \"remot\", \"remov\", \"remov\", \"remov\", \"right\", \"say\", \"seat\", \"ship\", \"size\", \"switch\", \"tire\", \"toyota\", \"unit\", \"unit\", \"unit\", \"wire\", \"work\", \"work\", \"work\", \"wrangler\"]}, \"R\": 7, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 3, 4, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el173461403708876943682594002766\", ldavis_el173461403708876943682594002766_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el173461403708876943682594002766\", ldavis_el173461403708876943682594002766_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el173461403708876943682594002766\", ldavis_el173461403708876943682594002766_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.105394 -0.157935       1        1  24.507930\n",
       "4      0.241710 -0.018244       2        1  20.964482\n",
       "2      0.119809  0.274177       3        1  18.593465\n",
       "3     -0.322527  0.145630       4        1  18.429788\n",
       "0     -0.144384 -0.243628       5        1  17.504335, topic_info=        Term          Freq         Total Category  logprob  loglift\n",
       "79      work  10535.000000  10535.000000  Default   7.0000   7.0000\n",
       "148   instal   3442.000000   3442.000000  Default   6.0000   6.0000\n",
       "674     seat   2609.000000   2609.000000  Default   5.0000   5.0000\n",
       "1464    bulb   2469.000000   2469.000000  Default   4.0000   4.0000\n",
       "26     model   2389.000000   2389.000000  Default   3.0000   3.0000\n",
       "...      ...           ...           ...      ...      ...      ...\n",
       "385     ship   1008.079247   1008.894287   Topic5  -4.2210   1.7419\n",
       "92      hole    969.968630    970.786927   Topic5  -4.2596   1.7419\n",
       "50      long   1217.068908   1416.257927   Topic5  -4.0326   1.5911\n",
       "84     light   2585.447549   5763.442214   Topic5  -3.2792   0.9411\n",
       "79      work   2344.919650  10535.855652   Topic5  -3.3768   0.2402\n",
       "\n",
       "[62 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "309       2  0.999516    accord\n",
       "428       1  0.998638    attach\n",
       "44        2  0.999596   batteri\n",
       "218       3  0.999558     black\n",
       "256       1  0.999277   bracket\n",
       "...     ...       ...       ...\n",
       "14        1  0.999751      wire\n",
       "79        1  0.198275      work\n",
       "79        4  0.579070      work\n",
       "79        5  0.222573      work\n",
       "340       3  0.998755  wrangler\n",
       "\n",
       "[82 rows x 3 columns], R=7, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 3, 4, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis1=pyLDAvis.gensim_models.prepare(lda_model,bow_corpus,dictionary, R=7)\n",
    "vis1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Intepretation of topics obtained:\n",
    "\n",
    "Now, let's try to identify the category of questions asked from the words provided for each topic:\n",
    "1. Topic 1 (install, come, mount, wire, need, light, work) - **Installation**\n",
    "2. Topic 2 (battery, say, unit, plug, light, power, charge) - **Battery & Charging**\n",
    "3. Topic 3 (size, tire, need, color, order, black, know) - **Tire**\n",
    "4. Topic 4 (work, seat, honda, model, chevi, ford, cover) - **Model specific**\n",
    "5. Topic 5 (light, bulb, work, toyota, dodge, inch, dimension) - **Cannot deduce a valid topic** <br>\n",
    "\n",
    "There are cases when the some of the topics obtained don't make much sense. One way to fix it would be to play around the hyperparameters in order to improve the results or sometimes its okay to just ignore them. Here, we can see that words in Topic 5 are not making much sense for categorizing it into specific category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the topics based on questions asked by Amazon customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is topic modelling?\n",
    "It is an unsupervised approach used for finding and observing the bunch of words (called Topics) in large clusters of texts.\n",
    "\n",
    "### Algorithm used:\n",
    "There are many algorithms available for Topic Modelling such as LSA (Latent Semantic Analysis), NMF (Non-Matrix Factorization) and LDA (Latent Dirichlet Algorithm). I'm using LDA as it provides more accurate results and scales well for large text corpuses.\n",
    "\n",
    "### A brief intro to LDA algorithm:\n",
    "LDA is a matrix factorization technique which assumes sentences are made up of mixture of words and tries to figure out what words would create those sentences in the first place. It is based on probabilistic graphical modelling. The algorithm works as follows:<br>\n",
    "1. In the initialization stage, each word is assigned to a random topic.\n",
    "2. Iteratively, the algorithm goes through each word and reassigns the word to a topic taking into consideration:<br>\n",
    "    What’s the probability of the word belonging to a topic?<br>\n",
    "    What’s the probability of the document to be generated by a topic?\n",
    "[Source]('https://nlpforhackers.io/topic-modeling/')\n",
    "\n",
    "### Data Source:\n",
    "http://jmcauley.ucsd.edu/data/amazon/qa/. Click on the Automotive category file to download the json file having the customer queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rupam\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rupam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read the zip files\n",
    "import gzip\n",
    "\n",
    "#LDA model\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Visualizing LDA\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Import the data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "data = getDF('qa_Automotive.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Extract the text column and assign it to an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_name):\n",
    "    data_text = data[['question']]\n",
    "    data_text['index'] = data_text.index\n",
    "    return data_text\n",
    "documents=prepare_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the most useful length to get?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are these cables made of copper or aluminum?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought the Red Extra Heavy Duty. Is that too...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi, Being 20ft 4gauge how heavy is this?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do these cables come with a bag?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  index\n",
       "0             What is the most useful length to get?      0\n",
       "1       Are these cables made of copper or aluminum?      1\n",
       "2  I bought the Red Extra Heavy Duty. Is that too...      2\n",
       "3           Hi, Being 20ft 4gauge how heavy is this?      3\n",
       "4                   Do these cables come with a bag?      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Reducing the words to its common  base form\n",
    "Now, we need to reduce the words which are in its plural or derivational forms into its common base form. This will help us collect the similar words from all the corpuses. Now the question is how do we do that? Here, stemming and lemmatization comes to the rescue.<br><br>\n",
    "**What is Stemming?** <br>\n",
    "The process of chopping off the ends of words, often includes the removal of derivational fixes. E.g. cats -> cat<br>\n",
    "There are two types of stemmer: SnowballStemmer and PorterStemmer. We will be using SnowballStemmer as it gives a more meaningful result compared to PorterStemmer().<br>\n",
    "\n",
    "**What is Lemmatization?** <br>\n",
    "The process of removal of inflectional endings only and returning the base or dictionary form of a word, which is known as lemma. E.g. running -> run.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to remove the stopwords and words whose length is less than or equal to three as they won't add much value to our model. We will implement it using gensim library as it already has a tokenization function and built-in library of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_shortwords(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['It', 'does', 'not', 'state', 'what', 'RPM', 'this', 'motor', 'is,', 'does', 'anyone', 'know?']\n",
      "\n",
      "\n",
      " Tokenized and lemmatized document: \n",
      "['state', 'motor', 'know']\n"
     ]
    }
   ],
   "source": [
    "sample = documents[documents['index'] == 25].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n Tokenized and lemmatized document: ')\n",
    "print(remove_stopwords_and_shortwords(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will apply the same on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['question'].map(remove_stopwords_and_shortwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the processed docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [use, length]\n",
       "1           [cabl, copper, aluminum]\n",
       "2    [buy, extra, heavi, duti, size]\n",
       "3                      [gaug, heavi]\n",
       "4                       [cabl, come]\n",
       "5        [wire, pair, surpris, wire]\n",
       "6                       [amp, handl]\n",
       "7              [cabl, boost, school]\n",
       "8                      [use, length]\n",
       "9           [cabl, copper, aluminum]\n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Build a dictionary of words present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 14469 words in the dictionary.\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "print('There are total '+ str(len(dictionary))+' words in the dictionary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 length\n",
      "1 use\n",
      "2 aluminum\n",
      "3 cabl\n",
      "4 copper\n",
      "5 buy\n",
      "6 duti\n",
      "7 extra\n",
      "8 heavi\n",
      "9 size\n",
      "10 gaug\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, word in dictionary.iteritems():\n",
    "    print(index, word)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Filter the dictionary based on frequency of words. \n",
    "Here, I have ignored the words which have appeared in less than 4 queries and the ones who are present in at most 50% of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of words in the dictionary after filtering: 4705\n"
     ]
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below=4, no_above=0.5)\n",
    "print('No. of words in the dictionary after filtering: '+ str(len(dictionary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Create a list having the index value and the frequency of the word for every question in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(5, 1), (6, 1), (7, 1), (8, 1), (9, 1)],\n",
       " [(8, 1), (10, 1)],\n",
       " [(3, 1), (11, 1)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"length\") appears 1 time.\n",
      "Word 1 (\"use\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_sample = bow_corpus[0]\n",
    "\n",
    "for i in range(len(bow_doc_sample)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_sample[i][0], \n",
    "                                                     dictionary[bow_doc_sample[i][0]], \n",
    "                                                     bow_doc_sample[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Implement the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(bow_corpus, num_topics=5, id2word=dictionary, passes=5,minimum_probability=0.01, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.041*\"light\" + 0.036*\"work\" + 0.036*\"bulb\" + 0.032*\"toyota\" + 0.019*\"dodg\" + 0.018*\"inch\" + 0.015*\"dimens\"\n",
      "Topic: 1 \n",
      "Words: 0.036*\"instal\" + 0.031*\"come\" + 0.025*\"mount\" + 0.025*\"need\" + 0.024*\"wire\" + 0.018*\"light\" + 0.015*\"work\"\n",
      "Topic: 2 \n",
      "Words: 0.031*\"size\" + 0.031*\"tire\" + 0.024*\"need\" + 0.018*\"color\" + 0.018*\"order\" + 0.017*\"black\" + 0.016*\"know\"\n",
      "Topic: 3 \n",
      "Words: 0.091*\"work\" + 0.036*\"seat\" + 0.033*\"model\" + 0.025*\"honda\" + 0.021*\"ford\" + 0.020*\"chevi\" + 0.019*\"cover\"\n",
      "Topic: 4 \n",
      "Words: 0.030*\"batteri\" + 0.027*\"say\" + 0.019*\"unit\" + 0.017*\"plug\" + 0.015*\"light\" + 0.015*\"power\" + 0.015*\"charg\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1,num_words=7):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Visualize the topics\n",
    "I have used pyLDAvis library which is designed to help users interpret the topics in a topic model that has been fit to a corpus of text data. The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization.[Source]('https://github.com/bmabey/pyLDAvis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el310427040379880566800504665\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el310427040379880566800504665_data = {\"mdsDat\": {\"x\": [-0.11576398396226788, -0.2227472357104045, -0.13412902460288026, 0.3224171241212757, 0.15022312015427694], \"y\": [0.17417914946494492, 0.007071917085564132, -0.26431720470396686, -0.1521083223263535, 0.23517446047981158], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [24.264387130737305, 20.576345443725586, 18.964826583862305, 18.642715454101562, 17.55172348022461]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [10520.0, 3454.0, 2600.0, 2454.0, 2381.0, 2326.0, 2212.0, 3453.470703125, 2365.141357421875, 2310.886474609375, 1037.67578125, 967.55029296875, 841.7749633789062, 810.1708984375, 2976.33056640625, 1266.1234130859375, 2341.27587890625, 1668.3426513671875, 1385.4287109375, 2383.44189453125, 2167.06103515625, 1386.5283203125, 1173.25146484375, 966.3923950195312, 763.5924682617188, 742.44482421875, 1560.7969970703125, 1229.423828125, 1236.4566650390625, 2325.30078125, 2313.606201171875, 1371.1361083984375, 1302.0196533203125, 1265.8280029296875, 993.3484497070312, 946.4601440429688, 1773.547119140625, 1113.018798828125, 1172.595703125, 2599.773193359375, 2380.35498046875, 1488.3795166015625, 1140.4609375, 989.17431640625, 953.5841064453125, 893.41259765625, 6674.48828125, 1851.8609619140625, 1501.248779296875, 1388.9417724609375, 2453.30810546875, 2211.36865234375, 1281.6136474609375, 1209.025390625, 1023.6058349609375, 1001.6278076171875, 963.7670288085938, 2846.1416015625, 2459.78857421875], \"Term\": [\"work\", \"instal\", \"seat\", \"bulb\", \"model\", \"size\", \"toyota\", \"instal\", \"mount\", \"wire\", \"switch\", \"remov\", \"bracket\", \"remot\", \"come\", \"includ\", \"need\", \"light\", \"work\", \"batteri\", \"say\", \"plug\", \"charg\", \"accord\", \"price\", \"water\", \"unit\", \"power\", \"light\", \"size\", \"tire\", \"color\", \"order\", \"black\", \"purchas\", \"wrangler\", \"need\", \"door\", \"know\", \"seat\", \"model\", \"chevi\", \"nissan\", \"mirror\", \"mat\", \"engin\", \"work\", \"honda\", \"ford\", \"cover\", \"bulb\", \"toyota\", \"dodg\", \"inch\", \"dimens\", \"ship\", \"hole\", \"light\", \"work\"], \"Total\": [10520.0, 3454.0, 2600.0, 2454.0, 2381.0, 2326.0, 2212.0, 3454.28662109375, 2365.956298828125, 2311.7001953125, 1038.49267578125, 968.383544921875, 842.588623046875, 810.9844970703125, 4805.97412109375, 1649.64111328125, 5533.97314453125, 5751.36328125, 10520.12890625, 2384.24609375, 2167.86669921875, 1387.336181640625, 1174.055419921875, 967.1991577148438, 764.3951416015625, 743.2509155273438, 1564.1544189453125, 1558.3631591796875, 5751.36328125, 2326.09228515625, 2314.399169921875, 1371.9273681640625, 1302.8154296875, 1266.6214599609375, 994.1458740234375, 947.2496948242188, 5533.97314453125, 1576.5908203125, 2585.66064453125, 2600.5810546875, 2381.164794921875, 1489.18505859375, 1141.2669677734375, 989.9815063476562, 954.3917846679688, 894.22021484375, 10520.12890625, 2645.15771484375, 1916.307861328125, 2522.412353515625, 2454.124267578125, 2212.18115234375, 1282.42529296875, 1209.841796875, 1024.41943359375, 1002.4419555664062, 964.5839233398438, 5751.36328125, 10520.12890625], \"loglift\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4158999919891357, 1.4157999753952026, 1.4157999753952026, 1.4154000282287598, 1.4153000116348267, 1.4151999950408936, 1.4151999950408936, 0.9369999766349792, 1.1516000032424927, 0.5559999942779541, 0.1785999983549118, -0.6111000180244446, 1.5807000398635864, 1.5807000398635864, 1.580399990081787, 1.580299973487854, 1.580199956893921, 1.5800000429153442, 1.5799000263214111, 1.5788999795913696, 1.3438999652862549, 0.043800000101327896, 1.6621999740600586, 1.6621999740600586, 1.6619999408721924, 1.6619999408721924, 1.6619999408721924, 1.6618000268936157, 1.6618000268936157, 0.5246999859809875, 1.3143999576568604, 0.8718000054359436, 1.6793999671936035, 1.6793999671936035, 1.6792000532150269, 1.6790000200271606, 1.6789000034332275, 1.6789000034332275, 1.6787999868392944, 1.2246999740600586, 1.323199987411499, 1.4356000423431396, 1.0829999446868896, 1.7396999597549438, 1.7396999597549438, 1.739400029182434, 1.739300012588501, 1.7391999959945679, 1.7391999959945679, 1.7391999959945679, 1.0364999771118164, 0.28679999709129333], \"logprob\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.316200017929077, -3.6947999000549316, -3.7179999351501465, -4.518599987030029, -4.588600158691406, -4.727799892425537, -4.76609992980957, -3.464900016784668, -4.3196001052856445, -3.704900026321411, -4.043799877166748, -4.229599952697754, -3.522200107574463, -3.6173999309539795, -4.063899993896484, -4.230999946594238, -4.424900054931641, -4.6605000495910645, -4.688499927520752, -3.945499897003174, -4.184199810028076, -4.178500175476074, -3.4653000831604004, -3.470400094985962, -3.993499994277954, -4.045300006866455, -4.073500156402588, -4.315899848937988, -4.364200115203857, -3.7362000942230225, -4.202099800109863, -4.150000095367432, -3.3366000652313232, -3.424799919128418, -3.894399881362915, -4.160600185394287, -4.3028998374938965, -4.339600086212158, -4.404799938201904, -2.3938000202178955, -3.6758999824523926, -3.8857998847961426, -3.9635000228881836, -3.3343000411987305, -3.4381000995635986, -3.983599901199341, -4.041900157928467, -4.208399772644043, -4.230100154876709, -4.268700122833252, -3.185800075531006, -3.331700086593628]}, \"token.table\": {\"Topic\": [2, 2, 3, 1, 5, 2, 4, 3, 1, 2, 3, 1, 2, 3, 4, 5, 5, 5, 3, 4, 4, 3, 4, 5, 2, 4, 5, 1, 2, 1, 1, 2, 3, 4, 5, 1, 2, 5, 4, 4, 4, 1, 1, 2, 3, 5, 4, 3, 2, 1, 2, 4, 2, 3, 1, 1, 2, 4, 5, 3, 1, 3, 5, 2, 3, 2, 1, 1, 4, 5, 3], \"Freq\": [0.9987601637840271, 0.9994773864746094, 0.999509334564209, 0.9993014335632324, 0.9995418787002563, 0.9991010427474976, 0.9992042183876038, 0.9993240237236023, 0.6192293167114258, 0.20287249982357025, 0.17790357768535614, 0.11259063333272934, 0.00039644588832743466, 0.2231990396976471, 0.5506633520126343, 0.11298707872629166, 0.9995905756950378, 0.9996683597564697, 0.7059535980224609, 0.2936716377735138, 0.998635470867157, 0.2160404473543167, 0.7832770943641663, 0.9993946552276611, 0.2997930943965912, 0.700147271156311, 0.9993042349815369, 0.7674396634101868, 0.23217171430587769, 0.9996275305747986, 0.08740513026714325, 0.21348509192466736, 0.45365580916404724, 0.1786777377128601, 0.06690746545791626, 0.2900182008743286, 0.21490557491779327, 0.4948391914367676, 0.9995895028114319, 0.9990085363388062, 0.9995108246803284, 0.9995958209037781, 0.42302337288856506, 0.1414896696805954, 0.3205653429031372, 0.11492647230625153, 0.9988898634910583, 0.9993740916252136, 0.999757707118988, 0.019250968471169472, 0.7886480093002319, 0.1912262886762619, 0.999483048915863, 0.9988473653793335, 0.9987860321998596, 0.9996039271354675, 0.9996002316474915, 0.9997765421867371, 0.9995591044425964, 0.9995304346084595, 0.9995256066322327, 0.99982750415802, 0.999466061592102, 0.9979833364486694, 0.0019179692026227713, 0.9983169436454773, 0.9996970891952515, 0.13165238499641418, 0.634402871131897, 0.23383744060993195, 0.9986807107925415], \"Term\": [\"accord\", \"batteri\", \"black\", \"bracket\", \"bulb\", \"charg\", \"chevi\", \"color\", \"come\", \"come\", \"come\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"dimens\", \"dodg\", \"door\", \"door\", \"engin\", \"ford\", \"ford\", \"hole\", \"honda\", \"honda\", \"inch\", \"includ\", \"includ\", \"instal\", \"know\", \"know\", \"know\", \"know\", \"know\", \"light\", \"light\", \"light\", \"mat\", \"mirror\", \"model\", \"mount\", \"need\", \"need\", \"need\", \"need\", \"nissan\", \"order\", \"plug\", \"power\", \"power\", \"power\", \"price\", \"purchas\", \"remot\", \"remov\", \"say\", \"seat\", \"ship\", \"size\", \"switch\", \"tire\", \"toyota\", \"unit\", \"unit\", \"water\", \"wire\", \"work\", \"work\", \"work\", \"wrangler\"]}, \"R\": 7, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 3, 4, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el310427040379880566800504665\", ldavis_el310427040379880566800504665_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el310427040379880566800504665\", ldavis_el310427040379880566800504665_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el310427040379880566800504665\", ldavis_el310427040379880566800504665_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.115764  0.174179       1        1  24.264387\n",
       "4     -0.222747  0.007072       2        1  20.576345\n",
       "2     -0.134129 -0.264317       3        1  18.964827\n",
       "3      0.322417 -0.152108       4        1  18.642715\n",
       "0      0.150223  0.235174       5        1  17.551723, topic_info=     Category          Freq      Term         Total  loglift  logprob\n",
       "term                                                                 \n",
       "79    Default  10520.000000      work  10520.000000   7.0000   7.0000\n",
       "148   Default   3454.000000    instal   3454.000000   6.0000   6.0000\n",
       "674   Default   2600.000000      seat   2600.000000   5.0000   5.0000\n",
       "1464  Default   2454.000000      bulb   2454.000000   4.0000   4.0000\n",
       "26    Default   2381.000000     model   2381.000000   3.0000   3.0000\n",
       "9     Default   2326.000000      size   2326.000000   2.0000   2.0000\n",
       "344   Default   2212.000000    toyota   2212.000000   1.0000   1.0000\n",
       "148    Topic1   3453.470703    instal   3454.286621   1.4159  -3.3162\n",
       "150    Topic1   2365.141357     mount   2365.956299   1.4158  -3.6948\n",
       "14     Topic1   2310.886475      wire   2311.700195   1.4158  -3.7180\n",
       "81     Topic1   1037.675781    switch   1038.492676   1.4154  -4.5186\n",
       "503    Topic1    967.550293     remov    968.383545   1.4153  -4.5886\n",
       "256    Topic1    841.774963   bracket    842.588623   1.4152  -4.7278\n",
       "221    Topic1    810.170898     remot    810.984497   1.4152  -4.7661\n",
       "11     Topic1   2976.330566      come   4805.974121   0.9370  -3.4649\n",
       "166    Topic1   1266.123413    includ   1649.641113   1.1516  -4.3196\n",
       "198    Topic1   2341.275879      need   5533.973145   0.5560  -3.7049\n",
       "84     Topic1   1668.342651     light   5751.363281   0.1786  -4.0438\n",
       "79     Topic1   1385.428711      work  10520.128906  -0.6111  -4.2296\n",
       "44     Topic2   2383.441895   batteri   2384.246094   1.5807  -3.5222\n",
       "36     Topic2   2167.061035       say   2167.866699   1.5807  -3.6174\n",
       "157    Topic2   1386.528320      plug   1387.336182   1.5804  -4.0639\n",
       "49     Topic2   1173.251465     charg   1174.055420   1.5803  -4.2310\n",
       "309    Topic2    966.392395    accord    967.199158   1.5802  -4.4249\n",
       "386    Topic2    763.592468     price    764.395142   1.5800  -4.6605\n",
       "156    Topic2    742.444824     water    743.250916   1.5799  -4.6885\n",
       "154    Topic2   1560.796997      unit   1564.154419   1.5789  -3.9455\n",
       "39     Topic2   1229.423828     power   1558.363159   1.3439  -4.1842\n",
       "84     Topic2   1236.456665     light   5751.363281   0.0438  -4.1785\n",
       "9      Topic3   2325.300781      size   2326.092285   1.6622  -3.4653\n",
       "339    Topic3   2313.606201      tire   2314.399170   1.6622  -3.4704\n",
       "264    Topic3   1371.136108     color   1371.927368   1.6620  -3.9935\n",
       "384    Topic3   1302.019653     order   1302.815430   1.6620  -4.0453\n",
       "218    Topic3   1265.828003     black   1266.621460   1.6620  -4.0735\n",
       "52     Topic3    993.348450   purchas    994.145874   1.6618  -4.3159\n",
       "340    Topic3    946.460144  wrangler    947.249695   1.6618  -4.3642\n",
       "198    Topic3   1773.547119      need   5533.973145   0.5247  -3.7362\n",
       "258    Topic3   1113.018799      door   1576.590820   1.3144  -4.2021\n",
       "21     Topic3   1172.595703      know   2585.660645   0.8718  -4.1500\n",
       "674    Topic4   2599.773193      seat   2600.581055   1.6794  -3.3366\n",
       "26     Topic4   2380.354980     model   2381.164795   1.6794  -3.4248\n",
       "743    Topic4   1488.379517     chevi   1489.185059   1.6792  -3.8944\n",
       "467    Topic4   1140.460938    nissan   1141.266968   1.6790  -4.1606\n",
       "757    Topic4    989.174316    mirror    989.981506   1.6789  -4.3029\n",
       "1341   Topic4    953.584106       mat    954.391785   1.6789  -4.3396\n",
       "213    Topic4    893.412598     engin    894.220215   1.6788  -4.4048\n",
       "79     Topic4   6674.488281      work  10520.128906   1.2247  -2.3938\n",
       "310    Topic4   1851.860962     honda   2645.157715   1.3232  -3.6759\n",
       "301    Topic4   1501.248779      ford   1916.307861   1.4356  -3.8858\n",
       "493    Topic4   1388.941772     cover   2522.412354   1.0830  -3.9635\n",
       "1464   Topic5   2453.308105      bulb   2454.124268   1.7397  -3.3343\n",
       "344    Topic5   2211.368652    toyota   2212.181152   1.7397  -3.4381\n",
       "400    Topic5   1281.613647      dodg   1282.425293   1.7394  -3.9836\n",
       "89     Topic5   1209.025391      inch   1209.841797   1.7393  -4.0419\n",
       "53     Topic5   1023.605835    dimens   1024.419434   1.7392  -4.2084\n",
       "385    Topic5   1001.627808      ship   1002.441956   1.7392  -4.2301\n",
       "92     Topic5    963.767029      hole    964.583923   1.7392  -4.2687\n",
       "84     Topic5   2846.141602     light   5751.363281   1.0365  -3.1858\n",
       "79     Topic5   2459.788574      work  10520.128906   0.2868  -3.3317, token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "309       2  0.998760    accord\n",
       "44        2  0.999477   batteri\n",
       "218       3  0.999509     black\n",
       "256       1  0.999301   bracket\n",
       "1464      5  0.999542      bulb\n",
       "49        2  0.999101     charg\n",
       "743       4  0.999204     chevi\n",
       "264       3  0.999324     color\n",
       "11        1  0.619229      come\n",
       "11        2  0.202872      come\n",
       "11        3  0.177904      come\n",
       "493       1  0.112591     cover\n",
       "493       2  0.000396     cover\n",
       "493       3  0.223199     cover\n",
       "493       4  0.550663     cover\n",
       "493       5  0.112987     cover\n",
       "53        5  0.999591    dimens\n",
       "400       5  0.999668      dodg\n",
       "258       3  0.705954      door\n",
       "258       4  0.293672      door\n",
       "213       4  0.998635     engin\n",
       "301       3  0.216040      ford\n",
       "301       4  0.783277      ford\n",
       "92        5  0.999395      hole\n",
       "310       2  0.299793     honda\n",
       "310       4  0.700147     honda\n",
       "89        5  0.999304      inch\n",
       "166       1  0.767440    includ\n",
       "166       2  0.232172    includ\n",
       "148       1  0.999628    instal\n",
       "...     ...       ...       ...\n",
       "150       1  0.999596     mount\n",
       "198       1  0.423023      need\n",
       "198       2  0.141490      need\n",
       "198       3  0.320565      need\n",
       "198       5  0.114926      need\n",
       "467       4  0.998890    nissan\n",
       "384       3  0.999374     order\n",
       "157       2  0.999758      plug\n",
       "39        1  0.019251     power\n",
       "39        2  0.788648     power\n",
       "39        4  0.191226     power\n",
       "386       2  0.999483     price\n",
       "52        3  0.998847   purchas\n",
       "221       1  0.998786     remot\n",
       "503       1  0.999604     remov\n",
       "36        2  0.999600       say\n",
       "674       4  0.999777      seat\n",
       "385       5  0.999559      ship\n",
       "9         3  0.999530      size\n",
       "81        1  0.999526    switch\n",
       "339       3  0.999828      tire\n",
       "344       5  0.999466    toyota\n",
       "154       2  0.997983      unit\n",
       "154       3  0.001918      unit\n",
       "156       2  0.998317     water\n",
       "14        1  0.999697      wire\n",
       "79        1  0.131652      work\n",
       "79        4  0.634403      work\n",
       "79        5  0.233837      work\n",
       "340       3  0.998681  wrangler\n",
       "\n",
       "[71 rows x 3 columns], R=7, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 3, 4, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis1=pyLDAvis.gensim.prepare(lda_model,bow_corpus,dictionary, R=7)\n",
    "vis1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Intepretation of topics obtained:\n",
    "\n",
    "Now, let's try to identify the category of questions asked from the words provided for each topic:\n",
    "1. Topic 1 (install, come, mount, wire, need, light, work) - **Installation**\n",
    "2. Topic 2 (battery, say, unit, plug, light, power, charge) - **Battery & Charging**\n",
    "3. Topic 3 (size, tire, need, color, order, black, know) - **Tire**\n",
    "4. Topic 4 (work, seat, honda, model, chevi, ford, cover) - **Model specific**\n",
    "5. Topic 5 (light, bulb, work, toyota, dodge, inch, dimension) - **Cannot deduce a valid topic** <br>\n",
    "\n",
    "There are cases when the some of the topics obtained don't make much sense. One way to fix it would be to play around the hyperparameters in order to improve the results or sometimes its okay to just ignore them. Here, we can see that words in Topic 5 are not making much sense for categorizing it into specific category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
